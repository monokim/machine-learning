{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Question & Answering Machine for Convaise.ipynb","provenance":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zdw6bkfeAYn0","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"4l3MqPxeAYn3","colab_type":"text"},"source":["Check If there is a GPU available."]},{"cell_type":"code","metadata":{"id":"n1U_spRMAYn4","colab_type":"code","outputId":"cc08b312-4d2b-48a2-98f5-edf850539353","executionInfo":{"status":"ok","timestamp":1584739304503,"user_tz":-60,"elapsed":3253,"user":{"displayName":"Hyunho Kim","photoUrl":"","userId":"04207700874606948738"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import torch\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print(torch.cuda.get_device_name(0), 'will be used.')\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device('cpu')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["No GPU available, using the CPU instead.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DxVfEMVkAYn8","colab_type":"text"},"source":["# Download [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/) Dataset"]},{"cell_type":"code","metadata":{"id":"11MQpg2gAYn8","colab_type":"code","outputId":"a77fd47a-144d-4118-8571-d7e1c05de2e0","executionInfo":{"status":"ok","timestamp":1584739310825,"user_tz":-60,"elapsed":4435,"user":{"displayName":"Hyunho Kim","photoUrl":"","userId":"04207700874606948738"}},"colab":{"base_uri":"https://localhost:8080/","height":474}},"source":["print('Downloading SQuAD 2.0 Dataset...')\n","\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","\n","print('Done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading SQuAD 2.0 Dataset...\n","--2020-03-20 21:21:47--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 42123633 (40M) [application/json]\n","Saving to: ‘train-v2.0.json’\n","\n","train-v2.0.json     100%[===================>]  40.17M  58.9MB/s    in 0.7s    \n","\n","2020-03-20 21:21:48 (58.9 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n","\n","--2020-03-20 21:21:49--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4370528 (4.2M) [application/json]\n","Saving to: ‘dev-v2.0.json’\n","\n","dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.09s   \n","\n","2020-03-20 21:21:49 (48.1 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q3EPdkXVAYoC","colab_type":"text"},"source":["# SQuAD json parser"]},{"cell_type":"code","metadata":{"id":"Uj3n4yMIAYoD","colab_type":"code","outputId":"52bac0ea-c0dd-411d-c8dd-313d00ca622c","executionInfo":{"status":"ok","timestamp":1584739587849,"user_tz":-60,"elapsed":570,"user":{"displayName":"Hyunho Kim","photoUrl":"","userId":"04207700874606948738"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["import json\n","\n","\"\"\"\n","Data format\n","\"data\": [{\"title\": \"Normans\", \n","          \"paragraphs\": [\n","                {\"qas\": [{\"question\": ... }, \"answers\": [{\"text\": ...}, {\"text\": ... } ]} \n","              ]\n","          ]\n","\"\"\"\n","# Read dataset\n","questions = []\n","answers = []\n","with open('./dev-v2.0.json') as f:\n","  dataset = json.load(f)\n","  for article in dataset['data']:\n","    for paragraph in article['paragraphs']:\n","      for qa in paragraph['qas']:\n","        questions.append(qa['question'])\n","        answers.append([a['text'] for a in qa['answers']])\n","\n","print(\"Dats size : %d\" % len(questions))\n","print(\"Question : \", questions[0])\n","print(\"Answer : \", answers[0])\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dats size : 11873\n","Question :  In what country is Normandy located?\n","Answer :  ['France', 'France', 'France', 'France']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DJ2Sv3TkAYoG","colab_type":"text"},"source":["# BERT Tokenizer\n","\n","Tokenize each words and convert to token IDs"]},{"cell_type":"code","metadata":{"id":"uiMqEtkd3T7o","colab_type":"code","colab":{}},"source":["# Install transformers by using pip\n","# !pip install transformers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrqOOw-LAYoH","colab_type":"code","outputId":"440fb1ba-1ca3-486d-a9ae-82fb3fa6daf3","executionInfo":{"status":"ok","timestamp":1584740047017,"user_tz":-60,"elapsed":746,"user":{"displayName":"Hyunho Kim","photoUrl":"","userId":"04207700874606948738"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from transformers import BertTokenizer\n","\n","# Load BERT Tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","print('Original : ', questions[0])\n","print('Tokenized : ', tokenizer.tokenize(questions[0]))\n","print('Token IDs : ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(questions[0])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original :  In what country is Normandy located?\n","Tokenized :  ['in', 'what', 'country', 'is', 'normandy', 'located', '?']\n","Token IDs :  [1999, 2054, 2406, 2003, 13298, 2284, 1029]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sL40H1W1AYoK","colab_type":"text"},"source":["Sentence to ID"]},{"cell_type":"code","metadata":{"id":"u2m4kI1kAYoL","colab_type":"code","outputId":"96ecdd15-aa27-476b-8f19-c5306ee22808","executionInfo":{"status":"ok","timestamp":1584740382298,"user_tz":-60,"elapsed":3894,"user":{"displayName":"Hyunho Kim","photoUrl":"","userId":"04207700874606948738"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["input_ids = []\n","\n","for q in questions:\n","    encoded_question = tokenizer.encode(q, add_special_tokens=True)\n","    input_ids.append(encoded_question)\n","    \n","print('original: ', questions[0])\n","print('id: ', input_ids[0])\n","print('Max sentence length: ', max([len(id) for id in input_ids]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["original:  In what country is Normandy located?\n","id:  [101, 1999, 2054, 2406, 2003, 13298, 2284, 1029, 102]\n","Max sentence length:  40\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SkHGEfJhAYoN","colab_type":"text"},"source":["Add padding and attention masks"]},{"cell_type":"code","metadata":{"id":"bvnwuYlZAYoO","colab_type":"code","colab":{}},"source":["def add_padding(input_ids):\n","    for input_id in input_ids:\n","        for i in range(64 - len(input_id)):\n","            input_id.insert(0, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHoWz1rtAYoQ","colab_type":"code","outputId":"7f1705a5-5186-4170-bf9e-31f7e72ab18f","colab":{}},"source":["MAX_LEN = 64\n","\n","# Add paddings('0')\n","add_padding(input_ids)\n","\n","print('After max question length: ', max([len(id) for id in input_ids]))\n","\n","attention_masks = []\n","\n","for id in input_ids:\n","    att_mask = [int(token_id) > 0 for token_id in id]\n","    attention_masks.append(att_mask)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["After max sentence length:  64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ca1FnQVUAYoS","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, labels, random_state=2020, test_size=0.1)\n","\n","train_masks, valid_masks, _, _ = train_test_split(attention_masks, labels, random_state=2020, test_size=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_AJNhyaAYoV","colab_type":"code","colab":{}},"source":["train_inputs = torch.tensor(train_inputs)\n","valid_inputs = torch.tensor(valid_inputs)\n","\n","train_labels = torch.tensor(train_labels)\n","valid_labels = torch.tensor(valid_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","valid_masks = torch.tensor(valid_masks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YeciXKeAYoX","colab_type":"code","colab":{}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n","valid_sampler = RandomSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pyvHK7gbAYoZ","colab_type":"text"},"source":["# Training\n","\n","BertForSequenceClassification"]},{"cell_type":"code","metadata":{"id":"QpfD-vUfAYoa","colab_type":"code","outputId":"d0dadd8f-b556-4ac7-c136-9bc82abe864b","colab":{}},"source":["from transformers import BertForQuestionAnswering, AdamW, BertConfig\n","\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","model.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0fVa1ATgAYod","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8\n","                 )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOPm2ntbAYof","colab_type":"code","colab":{}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 4\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rlsy2adMAYoi","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kJa6xacAYok","colab_type":"code","colab":{}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    elapsed_rounded = int(round(elapsed))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ErScfHqAYom","colab_type":"code","outputId":"4499f665-6b32-4507-b68a-e2276f416725","colab":{}},"source":["import random\n","\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:29.\n","  Batch    80  of    241.    Elapsed: 0:00:58.\n","  Batch   120  of    241.    Elapsed: 0:01:26.\n","  Batch   160  of    241.    Elapsed: 0:01:55.\n","  Batch   200  of    241.    Elapsed: 0:02:23.\n","  Batch   240  of    241.    Elapsed: 0:02:52.\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:02:52\n","\n","Running Validation...\n","  Accuracy: 0.83\n","  Validation took: 0:00:06\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:29.\n","  Batch    80  of    241.    Elapsed: 0:00:57.\n","  Batch   120  of    241.    Elapsed: 0:01:26.\n","  Batch   160  of    241.    Elapsed: 0:01:54.\n","  Batch   200  of    241.    Elapsed: 0:02:23.\n","  Batch   240  of    241.    Elapsed: 0:02:52.\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:02:53\n","\n","Running Validation...\n","  Accuracy: 0.84\n","  Validation took: 0:00:06\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:30.\n","  Batch    80  of    241.    Elapsed: 0:00:59.\n","  Batch   120  of    241.    Elapsed: 0:01:29.\n","  Batch   160  of    241.    Elapsed: 0:01:59.\n","  Batch   200  of    241.    Elapsed: 0:02:27.\n","  Batch   240  of    241.    Elapsed: 0:02:56.\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:02:57\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:00:06\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:30.\n","  Batch    80  of    241.    Elapsed: 0:00:59.\n","  Batch   120  of    241.    Elapsed: 0:01:28.\n","  Batch   160  of    241.    Elapsed: 0:01:57.\n","  Batch   200  of    241.    Elapsed: 0:02:26.\n","  Batch   240  of    241.    Elapsed: 0:02:54.\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:02:55\n","\n","Running Validation...\n","  Accuracy: 0.86\n","  Validation took: 0:00:06\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CAkvLl9pAYoo","colab_type":"text"},"source":["Plot"]},{"cell_type":"code","metadata":{"id":"Cmcj6mPBAYop","colab_type":"code","outputId":"d37bf53f-9a66-4b8e-b77c-ab288cee0141","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(loss_values, 'b-o')\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"0vyWFO7rAYor","colab_type":"text"},"source":["# test"]},{"cell_type":"code","metadata":{"id":"ZPBuLiXxAYos","colab_type":"code","outputId":"0d784160-d843-4dfb-df30-0ef72cff9000","colab":{}},"source":["import pandas as pd\n","\n","df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_note', 'sentence'])\n","\n","print('Number of test sentences: %d\\n' % df.shape[0])\n","\n","sentences = df.sentence.values\n","labels = df.label.values\n","\n","input_ids = []\n","\n","for s in sentences:\n","    encoded_sent = tokenizer.encode(\n","        s,\n","        add_special_tokens=True\n","    )\n","    input_ids.append(encoded_sent)\n","        \n","add_padding(input_ids)\n","\n","attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i > 0) for i in seq]\n","    attention_masks.append(seq_mask)\n","    \n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(labels)\n","\n","batch_size = 32\n","\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","\n","model.eval()\n","\n","predictions = []\n","true_labels = []\n","\n","for batch in prediction_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    with torch.no_grad():\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    \n","    logits = outputs[0]    \n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","\n","print(\"Done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of test sentences: 516\n","\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5XbUD7YpAYou","colab_type":"code","outputId":"94bcbe46-aef3-45e9-9808-8ceae8e6ebf5","colab":{}},"source":["print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Positive samples: 354 of 516 (68.60%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dQ6fdXYsAYow","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}